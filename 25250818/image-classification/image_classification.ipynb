{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%pip install torch\n",
    "%pip install torchvision\n",
    "%pip install torchsummary\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn\n",
    "%pip install pillow"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image"
   ],
   "id": "8963ba0132d2d6f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "device = 'cuda' if torch.cuda.is_available() else 'cpu'",
   "id": "7750e0e8013a036c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "device",
   "id": "bc25636b8649037c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for i in os.listdir('./afhq'):\n",
    "    for label in os.listdir(f'./afhq/{i}'):\n",
    "        for img in os.listdir(f'./afhq/{i}/{label}'):\n",
    "            image_paths.append(f'./afhq/{i}/{label}/{img}')\n",
    "            labels.append(label)\n",
    "\n",
    "df = pd.DataFrame(zip(image_paths, labels), columns=['image_path', 'label'])"
   ],
   "id": "92a79e60493542b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head()",
   "id": "8df295ccbcbde0f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['label'].unique()",
   "id": "9c324341f4c4fd83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train = df.sample(frac=0.7)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "val = test.sample(frac=0.5)\n",
    "test = test.drop(val.index)"
   ],
   "id": "232615c2e9a78877",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train.shape, val.shape, test.shape",
   "id": "65fc6211d97fe419",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df['label'])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "])"
   ],
   "id": "110f6a1d1232cdbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.labels = torch.Tensor(label_encoder.transform(dataframe['label'])).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataframe.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.dataframe.iloc[idx, 0]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image).to(device)\n",
    "        return image, label"
   ],
   "id": "4f4b4ea3530316cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataset = CustomImageDataset(train, transform)\n",
    "val_dataset = CustomImageDataset(val, transform)\n",
    "test_dataset = CustomImageDataset(test, transform)"
   ],
   "id": "46e70e5951a3e8cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "label_encoder.inverse_transform([0, 1, 2])",
   "id": "4d722bdb7e28aeb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_rows = 3\n",
    "n_cols = 3\n",
    "\n",
    "fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols)\n",
    "\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        img = Image.open(df.sample(n=1)['image_path'].iloc[0]).convert('RGB')\n",
    "        axs[row, col].imshow(img)\n",
    "        axs[row, col].axis('off')\n"
   ],
   "id": "d2bcff08579d0fb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "LR = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5"
   ],
   "id": "194f6c1da235898c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ],
   "id": "c8f7f4d8526a766d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),  # (32, 128, 128)\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (32, 64, 64)\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),  # (64, 64, 64)\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (64, 32, 32)\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),  # (128, 32, 32)\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (128, 16, 16)\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=(128 * 16 * 16), out_features=128),\n",
    "            nn.Linear(in_features=128, out_features=len(df['label'].unique())),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.sequential(x)"
   ],
   "id": "fa581ff526d67b5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = Net().to(device)",
   "id": "5497674f30e2669d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_size=(3, 128, 128))"
   ],
   "id": "86992914a742372b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- 多分类问题使用交叉熵损失函数（nn.CrossEntropyLoss()）\n",
    "- 二分类问题使用二分类损失函数（nn.BCELoss() 或者 nn.BCEWithLogitsLoss()）"
   ],
   "id": "fe0c7243fb3de27f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)"
   ],
   "id": "77368675f8a4f892",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total_loss_train_plot = []\n",
    "total_loss_val_plot = []\n",
    "\n",
    "total_acc_train_plot = []\n",
    "total_acc_val_plot = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss_train = 0\n",
    "    total_acc_train = 0\n",
    "    total_loss_val = 0\n",
    "    total_acc_val = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        labels = labels.long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        train_loss = loss_fn(outputs, labels)\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss_train += train_loss.item()\n",
    "        total_acc_train += labels.eq(outputs.argmax(dim=1)).sum().item()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for inputs, labels in val_loader:\n",
    "            labels = labels.long()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            val_loss = loss_fn(outputs, labels)\n",
    "\n",
    "            total_loss_val += val_loss.item()\n",
    "            total_acc_val += labels.eq(outputs.argmax(dim=1)).sum().item()\n",
    "\n",
    "    total_loss_train_plot.append(round(total_loss_train / 1000, 4))\n",
    "    total_loss_val_plot.append(round(total_loss_val / 1000, 4))\n",
    "\n",
    "    total_acc_train_plot.append(round(total_acc_train / train_dataset.__len__() * 100, 4))\n",
    "    total_acc_val_plot.append(round(total_acc_val / val_dataset.__len__() * 100, 4))\n",
    "\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}, train_loss: {total_loss_train_plot[-1]}, train_acc: {total_acc_train_plot[-1]}, val_loss: {total_loss_val_plot[-1]}, val_acc: {total_acc_val_plot[-1]}')\n"
   ],
   "id": "a1e4c484e3abf249",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "axs[0].plot(total_loss_train_plot, label='Train Loss')\n",
    "axs[0].plot(total_loss_val_plot, label='Validation Loss')\n",
    "axs[0].set_title('Training and Validation Loss over Epochs')\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend()\n",
    "\n",
    "\n",
    "axs[1].plot(total_acc_train_plot, label='Train Accuracy')\n",
    "axs[1].plot(total_acc_val_plot, label='Validation Accuracy')\n",
    "axs[1].set_title('Training and Validation Accuracy over Epochs')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].legend()\n"
   ],
   "id": "d9cf9dd3741f4431",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with torch.inference_mode():\n",
    "    total_loss_test = 0\n",
    "    total_acc_test = 0\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "        labels = labels.long()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        test_loss = loss_fn(outputs, labels)\n",
    "\n",
    "        total_loss_test += test_loss.item()\n",
    "        total_acc_test += labels.eq(outputs.argmax(dim=1)).sum().item()\n",
    "\n",
    "    print(f'test_loss: {round(total_loss_test / 1000, 4)}, test_acc: {round(total_acc_test / test_dataset.__len__() * 100, 4)}')"
   ],
   "id": "355e0fe67a447b43",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
