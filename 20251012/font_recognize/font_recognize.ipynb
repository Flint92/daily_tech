{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:09:38.525929Z",
     "start_time": "2025-10-17T19:09:37.673997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms"
   ],
   "id": "8054d353e5f2612f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:09:38.541702Z",
     "start_time": "2025-10-17T19:09:38.529289Z"
    }
   },
   "cell_type": "code",
   "source": "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'",
   "id": "be39bea8a4a400cd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:09:38.569674Z",
     "start_time": "2025-10-17T19:09:38.567911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LR = 1e-3"
   ],
   "id": "81b9573ccf7a0aad",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:09:38.588630Z",
     "start_time": "2025-10-17T19:09:38.586847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])"
   ],
   "id": "614b9940800f5355",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:09:38.628603Z",
     "start_time": "2025-10-17T19:09:38.612360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 下载数据集\n",
    "train_set = datasets.MNIST('./data', train=True, download=True, transform=trans)\n",
    "test_set = datasets.MNIST('./data', train=False, download=True, transform=trans)\n",
    "\n",
    "# 加载数据集\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "id": "9fd4431b99d395a6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:09:38.661518Z",
     "start_time": "2025-10-17T19:09:38.652861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('./data/MNIST/raw/train-images-idx3-ubyte', 'rb') as f:\n",
    "    train_images = f.read()"
   ],
   "id": "66c93f63c533ef38",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:09:38.685883Z",
     "start_time": "2025-10-17T19:09:38.684095Z"
    }
   },
   "cell_type": "code",
   "source": "train_image1 = [int(str(i).encode('ascii'), 16) for i in train_images[16:16+784]]",
   "id": "186283f78b8448d2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:09:38.745103Z",
     "start_time": "2025-10-17T19:09:38.701568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "train_image1_np = np.array(train_image1, dtype=np.uint16).reshape(28, 28, 1)\n",
    "cv2.imwrite('train_image1.jpg', train_image1_np)"
   ],
   "id": "37b72258a2bd2e22",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.005] global loadsave.cpp:1063 imwrite_ Unsupported depth image for selected encoder is fallbacked to CV_8U.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:09:38.752957Z",
     "start_time": "2025-10-17T19:09:38.749667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Digit(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Digit, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(in_features=20*10*10, out_features=500)\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        input_size = x.size(0) # batch size\n",
    "        x = self.conv1(x) # batch*1*28*28 => batch*10*24*24(28-5+1) # (输入大小 - 卷积核大小 + 1)\n",
    "        x = F.relu(x) # batch*10*24*24\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2) # batch*10*24*24 => batch*10*12*12 # (输入大小 - 池化核大小) / 步长 + 1\n",
    "\n",
    "        x = self.conv2(x) # batch*10*12*12 => batch*20*10*10\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.view(input_size, -1) # flatten (-1表示自动计算维度): batch*20*10*10 => batch*2000\n",
    "\n",
    "        x = self.fc1(x) # batch*2000 => batch*500\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x) # batch*500 => batch*10\n",
    "\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return output\n"
   ],
   "id": "c377de726f218d81",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:09:38.784316Z",
     "start_time": "2025-10-17T19:09:38.771839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Digit().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ],
   "id": "1c0ba3fa252f527c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:09:38.799181Z",
     "start_time": "2025-10-17T19:09:38.797350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output = model(data)\n",
    "                loss = F.cross_entropy(output, target)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if batch_idx % 3000 == 0:\n",
    "                    print(f\"Train Epoch: {epoch} \\t Loss: {loss.item():.6f}\")\n"
   ],
   "id": "417bdd2f0ca6228",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:09:38.811487Z",
     "start_time": "2025-10-17T19:09:38.809405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_model(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.inference_mode():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target).item() # 将一批的损失相加\n",
    "            pred = output.argmax(dim=1, keepdim=True) # 找到概率最大的下标\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {100. * correct / len(test_loader.dataset):.0f}%\\n')"
   ],
   "id": "cff802573775ae80",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:11:28.508466Z",
     "start_time": "2025-10-17T19:09:38.831280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_model(model, device, train_loader, optimizer, epoch)\n",
    "    test_model(model, device, test_loader)"
   ],
   "id": "97c54df7d02ff218",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \t Loss: 2.299899\n",
      "Train Epoch: 1 \t Loss: 0.021098\n",
      "\n",
      "Test set: Average loss: 0.0031, Accuracy: 98%\n",
      "\n",
      "Train Epoch: 2 \t Loss: 0.002281\n",
      "Train Epoch: 2 \t Loss: 0.000654\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 99%\n",
      "\n",
      "Train Epoch: 3 \t Loss: 0.039515\n",
      "Train Epoch: 3 \t Loss: 0.000204\n",
      "\n",
      "Test set: Average loss: 0.0026, Accuracy: 99%\n",
      "\n",
      "Train Epoch: 4 \t Loss: 0.003302\n",
      "Train Epoch: 4 \t Loss: 0.000022\n",
      "\n",
      "Test set: Average loss: 0.0025, Accuracy: 99%\n",
      "\n",
      "Train Epoch: 5 \t Loss: 0.000461\n",
      "Train Epoch: 5 \t Loss: 0.000140\n",
      "\n",
      "Test set: Average loss: 0.0041, Accuracy: 99%\n",
      "\n",
      "Train Epoch: 6 \t Loss: 0.013551\n",
      "Train Epoch: 6 \t Loss: 0.003990\n",
      "\n",
      "Test set: Average loss: 0.0038, Accuracy: 99%\n",
      "\n",
      "Train Epoch: 7 \t Loss: 0.000042\n",
      "Train Epoch: 7 \t Loss: 0.000306\n",
      "\n",
      "Test set: Average loss: 0.0026, Accuracy: 99%\n",
      "\n",
      "Train Epoch: 8 \t Loss: 0.000001\n",
      "Train Epoch: 8 \t Loss: 0.000006\n",
      "\n",
      "Test set: Average loss: 0.0035, Accuracy: 99%\n",
      "\n",
      "Train Epoch: 9 \t Loss: 0.000010\n",
      "Train Epoch: 9 \t Loss: 0.000002\n",
      "\n",
      "Test set: Average loss: 0.0043, Accuracy: 99%\n",
      "\n",
      "Train Epoch: 10 \t Loss: 0.000006\n",
      "Train Epoch: 10 \t Loss: 0.000067\n",
      "\n",
      "Test set: Average loss: 0.0050, Accuracy: 99%\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
