{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%pip install opendatasets\n",
    "import opendatasets as od\n",
    "\n",
    "od.download('https://www.kaggle.com/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%pip install torch\n",
    "%pip install torchvision\n",
    "%pip install torchsummary\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn\n",
    "%pip install transformers"
   ],
   "id": "4e8dcf021e4bfd27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T18:32:36.726118Z",
     "start_time": "2025-09-02T18:32:34.704924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from torch.optim import Adam\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "1ce77b51e29fb7f9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T18:32:40.998340Z",
     "start_time": "2025-09-02T18:32:40.969886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device"
   ],
   "id": "8d8c608d7fe62d27",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T18:32:44.092180Z",
     "start_time": "2025-09-02T18:32:44.037800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_json('./news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json', lines=True)\n",
    "df.head()\n"
   ],
   "id": "ffa3b3c6c053a34e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T18:32:46.432092Z",
     "start_time": "2025-09-02T18:32:46.407893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.drop(['article_link'], axis=1, inplace=True)\n",
    "df.shape"
   ],
   "id": "6e7fc20d62cf16ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26708, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T18:32:48.704809Z",
     "start_time": "2025-09-02T18:32:48.697599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['headline'], df['is_sarcastic'], test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ],
   "id": "f7c9c7b9999564ee",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')\n",
    "bert = AutoModelForMaskedLM.from_pretrained('google-bert/bert-base-uncased')"
   ],
   "id": "53aa56d16d8c3564",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T18:32:55.230526Z",
     "start_time": "2025-09-02T18:32:55.227705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = tokenizer(\n",
    "            self.X.iloc[idx],\n",
    "            max_length=100,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        X = {k: v.squeeze(0) for k, v in X.items()}\n",
    "        label = torch.tensor(self.Y[idx], dtype=torch.float32)\n",
    "        return X, label"
   ],
   "id": "87b5ed9dfe76e0f4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T18:32:57.300655Z",
     "start_time": "2025-09-02T18:32:57.298345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = dataset(X_train, y_train)\n",
    "val_data = dataset(X_val, y_val)\n",
    "test_data = dataset(X_test, y_test)"
   ],
   "id": "edb8a0c2acbfcda5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T18:33:00.219098Z",
     "start_time": "2025-09-02T18:33:00.216699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SZIE = 32\n",
    "EPOCHS = 10\n",
    "LR = 1e-4"
   ],
   "id": "153a25ba28163d1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T18:33:02.088054Z",
     "start_time": "2025-09-02T18:33:02.084280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SZIE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=BATCH_SZIE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SZIE, shuffle=True)"
   ],
   "id": "3fcd8669a346859e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T18:33:03.839992Z",
     "start_time": "2025-09-02T18:33:03.837184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(Net, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(30522, 384)\n",
    "        self.fc2 = nn.Linear(384, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)[0][:,0]\n",
    "        pooled_output = self.fc1(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = self.fc2(pooled_output)\n",
    "        return self.sigmoid(pooled_output)\n"
   ],
   "id": "e91c053ccc2bfc63",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T18:33:06.383619Z",
     "start_time": "2025-09-02T18:33:06.176519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = Net(bert).to(device)"
   ],
   "id": "98e702ae160f3d5d",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T18:33:08.146117Z",
     "start_time": "2025-09-02T18:33:08.143365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)"
   ],
   "id": "31b82f204371dcf1",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T18:55:45.129903Z",
     "start_time": "2025-09-02T18:33:22.266901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_loss_train_plot = []\n",
    "total_loss_val_plot = []\n",
    "total_acc_train_plot = []\n",
    "total_acc_val_plot = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss_train = 0\n",
    "    total_loss_val = 0\n",
    "    total_acc_train = 0\n",
    "    total_acc_val = 0\n",
    "\n",
    "\n",
    "    for idx, data in enumerate(train_dataloader):\n",
    "        inputs, labels = data\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs['input_ids'].squeeze(1), inputs['attention_mask'].squeeze(1)).squeeze(1)\n",
    "        train_loss = loss_fn(outputs, labels)\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss_train += train_loss.item()\n",
    "        total_acc_train += (outputs.round() == labels).sum().item()\n",
    "\n",
    "    with (torch.inference_mode()):\n",
    "        for idx, data in enumerate(val_dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "            val_outputs = model(inputs['input_ids'].squeeze(1), inputs['attention_mask'].squeeze(1)).squeeze(1)\n",
    "            total_loss_val += loss_fn(val_outputs, labels).item()\n",
    "            total_acc_val += (val_outputs.round() == labels).sum().item()\n",
    "\n",
    "    total_loss_train_plot.append(round(total_loss_train / 1000, 4))\n",
    "    total_loss_val_plot.append(round(total_loss_val / 1000, 4))\n",
    "\n",
    "    total_acc_train_plot.append(round(total_acc_train / train_data.__len__() * 100, 4))\n",
    "    total_acc_val_plot.append(round(total_acc_val / val_data.__len__() * 100, 4))\n",
    "\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}, train_loss: {total_loss_train_plot[-1]}, train_acc: {total_acc_train_plot[-1]}, val_loss: {total_loss_val_plot[-1]}, val_acc: {total_acc_val_plot[-1]}')"
   ],
   "id": "73e5a54309d0f0e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, train_loss: 25.5487, train_acc: 56.2878, val_loss: 5.5521, val_acc: 55.8662\n",
      "Epoch 2/10, train_loss: 25.5821, train_acc: 56.2878, val_loss: 5.5521, val_acc: 55.8662\n",
      "Epoch 3/10, train_loss: 25.5933, train_acc: 56.2878, val_loss: 5.5521, val_acc: 55.8662\n",
      "Epoch 4/10, train_loss: 25.5821, train_acc: 56.2878, val_loss: 5.5385, val_acc: 55.8662\n",
      "Epoch 5/10, train_loss: 25.571, train_acc: 56.2878, val_loss: 5.5521, val_acc: 55.8662\n",
      "Epoch 6/10, train_loss: 25.5821, train_acc: 56.2878, val_loss: 5.5656, val_acc: 55.8662\n",
      "Epoch 7/10, train_loss: 25.5821, train_acc: 56.2878, val_loss: 5.5385, val_acc: 55.8662\n",
      "Epoch 8/10, train_loss: 25.5598, train_acc: 56.2878, val_loss: 5.5385, val_acc: 55.8662\n",
      "Epoch 9/10, train_loss: 25.571, train_acc: 56.2878, val_loss: 5.5656, val_acc: 55.8662\n",
      "Epoch 10/10, train_loss: 25.571, train_acc: 56.2878, val_loss: 5.5656, val_acc: 55.8662\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
